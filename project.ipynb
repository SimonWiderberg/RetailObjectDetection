{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0525f99-7a01-4da0-b0d6-6547a5bbe6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "718678fd-dbce-4aca-8643-a2ae36f5ba04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/shinolim/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2024-10-7 Python-3.11.9 torch-2.3.1 CPU\n",
      "\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.1M/14.1M [00:32<00:00, 454kB/s]\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n",
      "image 1/1: 720x1280 2 persons, 1 tie, 1 cell phone\n",
      "Speed: 3209.3ms pre-process, 85.7ms inference, 12.8ms NMS per image at shape (1, 3, 384, 640)\n",
      "Saved 1 image to \u001b[1mruns/detect/exp\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>confidence</th>\n",
       "      <th>class</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>745.578674</td>\n",
       "      <td>48.470337</td>\n",
       "      <td>1142.694214</td>\n",
       "      <td>720.000000</td>\n",
       "      <td>0.868910</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124.744324</td>\n",
       "      <td>197.334564</td>\n",
       "      <td>844.396912</td>\n",
       "      <td>716.650513</td>\n",
       "      <td>0.630324</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>441.238708</td>\n",
       "      <td>439.350647</td>\n",
       "      <td>498.380737</td>\n",
       "      <td>708.570984</td>\n",
       "      <td>0.616793</td>\n",
       "      <td>27</td>\n",
       "      <td>tie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>594.081787</td>\n",
       "      <td>377.300323</td>\n",
       "      <td>635.423950</td>\n",
       "      <td>437.147797</td>\n",
       "      <td>0.274014</td>\n",
       "      <td>67</td>\n",
       "      <td>cell phone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         xmin        ymin         xmax        ymax  confidence  class  \\\n",
       "0  745.578674   48.470337  1142.694214  720.000000    0.868910      0   \n",
       "1  124.744324  197.334564   844.396912  716.650513    0.630324      0   \n",
       "2  441.238708  439.350647   498.380737  708.570984    0.616793     27   \n",
       "3  594.081787  377.300323   635.423950  437.147797    0.274014     67   \n",
       "\n",
       "         name  \n",
       "0      person  \n",
       "1      person  \n",
       "2         tie  \n",
       "3  cell phone  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "\n",
    "# Images\n",
    "imgs = ['https://ultralytics.com/images/zidane.jpg']  # batch of images\n",
    "\n",
    "# Inference\n",
    "results = model(imgs)\n",
    "\n",
    "# Results\n",
    "results.print()\n",
    "results.save()  # or .show()\n",
    "\n",
    "results.xyxy[0]  # img1 predictions (tensor)\n",
    "results.pandas().xyxy[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b4d01d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['info', 'licenses', 'categories', '__raw_Chinese_name_df', 'images', 'annotations'])\n"
     ]
    }
   ],
   "source": [
    "#validation dataset\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "json_file_path = 'instances_val2019.json'\n",
    "\n",
    "with open(json_file_path) as json_data:\n",
    "    data = json.load(json_data)\n",
    "\n",
    "print(data.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cfe3f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      file_name  width  height     id level\n",
      "0     20180827-16-07-06-756.jpg   1850    1850    220  easy\n",
      "1     20180827-16-07-10-756.jpg   1840    1840    221  easy\n",
      "2     20180827-16-24-37-306.jpg   1826    1826    222  easy\n",
      "3     20180827-16-24-44-306.jpg   1829    1829    223  easy\n",
      "4     20180827-16-24-53-306.jpg   1826    1826    224  easy\n",
      "...                         ...    ...     ...    ...   ...\n",
      "5995  20181024-15-23-05-131.jpg   1813    1813  30609  hard\n",
      "5996  20181024-15-37-14-136.jpg   1821    1821  30613  hard\n",
      "5997  20181024-15-37-31-136.jpg   1832    1832  30614  hard\n",
      "5998  20181024-15-37-46-136.jpg   1830    1830  30615  hard\n",
      "5999  20181024-15-57-25-126.jpg   1808    1808  30616  hard\n",
      "\n",
      "[6000 rows x 5 columns]\n",
      "Index(['file_name', 'width', 'height', 'id', 'level'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data['images'])\n",
    "print(df)\n",
    "print(df.keys())"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 50,
>>>>>>> 194229f1a74ae104d9b84e317e38029c5a1177e8
   "id": "e39a6d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "2000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "#view number of images in each level in val dataset\n",
    "easy_images = df[df['level'] == 'easy']\n",
    "medium_images = df[df['level'] == 'medium']\n",
    "hard_images = df[df['level'] == 'hard']\n",
    "\n",
    "print(len(easy_images))\n",
    "print(len(medium_images))\n",
    "print(len(hard_images))\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 51,
   "id": "1acdf962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      file_name  width  height     id level\n",
      "0     20180827-16-07-06-756.jpg   1850    1850    220  easy\n",
      "1     20180827-16-07-10-756.jpg   1840    1840    221  easy\n",
      "2     20180827-16-24-37-306.jpg   1826    1826    222  easy\n",
      "3     20180827-16-24-44-306.jpg   1829    1829    223  easy\n",
      "4     20180827-16-24-53-306.jpg   1826    1826    224  easy\n",
      "...                         ...    ...     ...    ...   ...\n",
      "5995  20181024-15-23-05-131.jpg   1813    1813  30609  hard\n",
      "5996  20181024-15-37-14-136.jpg   1821    1821  30613  hard\n",
      "5997  20181024-15-37-31-136.jpg   1832    1832  30614  hard\n",
      "5998  20181024-15-37-46-136.jpg   1830    1830  30615  hard\n",
      "5999  20181024-15-57-25-126.jpg   1808    1808  30616  hard\n",
      "\n",
      "[6000 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "images_df = pd.DataFrame(data['images'])\n",
    "print(images_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
>>>>>>> 194229f1a74ae104d9b84e317e38029c5a1177e8
   "id": "8d9f5828",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split validation data into corresponding levels\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "val2019_dir = 'val2019'\n",
    "\n",
    "for level in ['easy', 'medium', 'hard']:\n",
    "    level_dir = os.path.join(val2019_dir, level)\n",
    "    if not os.path.exists(level_dir):\n",
    "        os.makedirs(level_dir)\n",
    "\n",
    "# Move images to respective level folders\n",
    "for image_info in data['images']:\n",
    "    file_name = image_info['file_name']\n",
    "    level = image_info.get('level')  # Get the level ('easy', 'medium', or 'hard')\n",
    "\n",
    "    if level in ['easy', 'medium', 'hard']:\n",
    "        src = os.path.join(val2019_dir, file_name)\n",
    "        dest = os.path.join(val2019_dir, level, file_name)\n",
    "        \n",
    "        # Check if the image file exists before moving\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, dest)\n",
    "        else:\n",
    "            print(f\"Image file {file_name} not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c936fe1-0e94-4374-82ab-2eeb47cd08ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['info', 'licenses', 'categories', '__raw_Chinese_name_df', 'images', 'annotations'])\n",
      "8000\n",
      "8000\n",
      "8000\n"
     ]
    }
   ],
   "source": [
    "#test dataset\n",
    "json_file_path = 'instances_test2019.json'\n",
    "\n",
    "with open(json_file_path) as json_data:\n",
    "    data = json.load(json_data)\n",
    "\n",
    "print(data.keys())\n",
    "\n",
    "test_df = pd.DataFrame(data['images'])\n",
    "#view number of images in each level in test dataset\n",
    "easy_images = test_df[test_df['level'] == 'easy']\n",
    "medium_images = test_df[test_df['level'] == 'medium']\n",
    "hard_images = test_df[test_df['level'] == 'hard']\n",
    "\n",
    "print(len(easy_images))\n",
    "print(len(medium_images))\n",
    "print(len(hard_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e844c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split test data into corresponding levels\n",
    "test2019_dir = 'test2019'\n",
    "\n",
    "for level in ['easy', 'medium', 'hard']:\n",
    "    level_dir = os.path.join(test2019_dir, level)\n",
    "    if not os.path.exists(level_dir):\n",
    "        os.makedirs(level_dir)\n",
    "\n",
    "# Move images to respective level folders\n",
    "for image_info in data['images']:\n",
    "    file_name = image_info['file_name']\n",
    "    level = image_info.get('level')  # Get the level ('easy', 'medium', or 'hard')\n",
    "\n",
    "    if level in ['easy', 'medium', 'hard']:\n",
    "        src = os.path.join(test2019_dir, file_name)\n",
    "        dest = os.path.join(test2019_dir, level, file_name)\n",
    "        \n",
    "        # Check if the image file exists before moving\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, dest)\n",
    "        else:\n",
    "            print(f\"Image file {file_name} not found.\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 52,
>>>>>>> 194229f1a74ae104d9b84e317e38029c5a1177e8
   "id": "ab81992b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images successfully copied to newtrain_dataset\n"
     ]
    }
   ],
   "source": [
    "#create a new training dataset (with train2019, medium level of val2019, medium level of test2019)\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Paths to the directories\n",
    "train2019_dir = 'train2019'\n",
    "val2019_medium_dir = 'val2019/medium'\n",
    "test2019_medium_dir = 'test2019/medium'\n",
    "\n",
    "# New directory path\n",
    "new_dir = 'train_new'\n",
    "\n",
    "# Create the new directory if it doesn't exist\n",
    "if not os.path.exists(new_dir):\n",
    "    os.makedirs(new_dir)\n",
    "\n",
    "# Function to copy files from a directory to the new directory\n",
    "def copy_images(src_dir, dest_dir):\n",
    "    for file_name in os.listdir(src_dir):\n",
    "        src_file = os.path.join(src_dir, file_name)\n",
    "        dest_file = os.path.join(dest_dir, file_name)\n",
    "        if os.path.isfile(src_file):\n",
    "            shutil.copy(src_file, dest_file)\n",
    "\n",
    "# Copy images from train2019, val2019/medium, and test2019/medium\n",
    "copy_images(train2019_dir, new_dir)\n",
    "copy_images(val2019_medium_dir, new_dir)\n",
    "copy_images(test2019_medium_dir, new_dir)\n",
    "\n",
    "print(f\"Images successfully copied to {new_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
   "id": "8d9fa471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'train2019' has been successfully duplicated and renamed to 'singleobject'.\n"
     ]
    }
   ],
   "source": [
    "#Task 1: Train model on single object\n",
    "#duplicate train2019 into singleobject\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "original_folder = Path(\"train2019\")\n",
    "new_folder = Path(\"singleobject\")\n",
    "\n",
    "# Check if the original folder exists\n",
    "if original_folder.exists() and original_folder.is_dir():\n",
    "    # Copy the entire directory tree to the new folder\n",
    "    shutil.copytree(original_folder, new_folder)\n",
    "    print(f\"Folder '{original_folder}' has been successfully duplicated and renamed to '{new_folder}'.\")\n",
    "else:\n",
    "    print(f\"The folder '{original_folder}' does not exist or is not a directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
=======
   "execution_count": 53,
>>>>>>> 194229f1a74ae104d9b84e317e38029c5a1177e8
   "id": "2325c072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split completed: 48365 training images and 5374 temporary images.\n"
     ]
    }
   ],
   "source": [
    "#split singleobject dataset into 90% train / 5% val / 5% test\n",
    "from pathlib import Path\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "original_dataset_dir = 'singleobject'\n",
    "data_path = Path.cwd()\n",
    "\n",
    "# List all images in the original dataset directory\n",
    "all_images = os.listdir(original_dataset_dir)\n",
    "\n",
    "def fill_sub_dir(sub_dir, file_subset):\n",
    "    \"\"\"This function copies files to a specified <sub_dir>.\"\"\"\n",
    "    for file_name in file_subset:\n",
    "        # Create source and destination paths\n",
    "        src_file_path = Path(original_dataset_dir) / file_name\n",
    "        dest_file_path = data_path / sub_dir / file_name\n",
    "        # Copy the file\n",
    "        shutil.copyfile(src_file_path, dest_file_path)\n",
    "\n",
    "split_ratio_big_dataset = 0.1  # Adjust the split ratio as needed\n",
    "\n",
    "if split_ratio_big_dataset is None:\n",
    "    raise ValueError(\"`split_ratio_big_dataset` must have a value between 0 and 1.\")\n",
    "\n",
    "# Split it\n",
    "train, temp = train_test_split(all_images, test_size=split_ratio_big_dataset, random_state=3)\n",
    "\n",
    "subdirectories = {\n",
    "    \"singleobject_train\": train,\n",
    "    \"singleobject_temp\": temp,\n",
    "}\n",
    "\n",
    "# Create subdirectories if they don't exist\n",
    "for subdirectory in subdirectories.keys():\n",
    "    subdirectory_path = data_path / subdirectory\n",
    "    subdirectory_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Copy files to the respective subdirectories\n",
    "for sub_dir, file_subset in subdirectories.items():\n",
    "    fill_sub_dir(sub_dir, file_subset)\n",
    "\n",
    "print(f\"Split completed: {len(train)} training images and {len(temp)} temporary images.\")\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 20,
=======
   "execution_count": 54,
>>>>>>> 194229f1a74ae104d9b84e317e38029c5a1177e8
   "id": "0a570af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Split completed: 2687 test images and 2687 val images.\n",
      "Removed temp and singleobject dataset\n"
=======
      "Split completed: 2687 test images and 2687 val images.\n"
>>>>>>> 194229f1a74ae104d9b84e317e38029c5a1177e8
     ]
    }
   ],
   "source": [
    "#split test and val\n",
    "original_dataset_dir = 'singleobject_temp'\n",
    "temp_images = os.listdir(original_dataset_dir)\n",
    "val, test = train_test_split(temp_images, test_size=0.5, random_state=3)\n",
    "\n",
    "subdirectories = {\n",
    "    \"singleobject_val\": val,\n",
    "    \"singleobject_test\": test,\n",
    "}\n",
    "\n",
    "# Create subdirectories if they don't exist\n",
    "for subdirectory in subdirectories.keys():\n",
    "    subdirectory_path = data_path / subdirectory\n",
    "    subdirectory_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Copy files to the respective subdirectories\n",
    "for sub_dir, file_subset in subdirectories.items():\n",
    "    fill_sub_dir(sub_dir, file_subset)\n",
    "\n",
    "print(f\"Split completed: {len(test)} test images and {len(val)} val images.\")\n",
    "\n",
    "shutil.rmtree(original_dataset_dir)\n",
    "shutil.rmtree('singleobject')\n",
    "print(f\"Removed temp and singleobject dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb981cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
