{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0525f99-7a01-4da0-b0d6-6547a5bbe6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "718678fd-dbce-4aca-8643-a2ae36f5ba04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\wider/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2024-10-7 Python-3.11.9 torch-2.3.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n",
      "image 1/1: 720x1280 2 persons, 1 tie, 1 cell phone\n",
      "Speed: 1230.4ms pre-process, 108.2ms inference, 9.0ms NMS per image at shape (1, 3, 384, 640)\n",
      "Saved 1 image to \u001b[1mruns\\detect\\exp7\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>confidence</th>\n",
       "      <th>class</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>745.578552</td>\n",
       "      <td>48.470337</td>\n",
       "      <td>1142.694336</td>\n",
       "      <td>720.000000</td>\n",
       "      <td>0.868910</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124.744202</td>\n",
       "      <td>197.334534</td>\n",
       "      <td>844.397156</td>\n",
       "      <td>716.650574</td>\n",
       "      <td>0.630325</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>441.238708</td>\n",
       "      <td>439.350647</td>\n",
       "      <td>498.380798</td>\n",
       "      <td>708.570984</td>\n",
       "      <td>0.616793</td>\n",
       "      <td>27</td>\n",
       "      <td>tie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>594.081848</td>\n",
       "      <td>377.300415</td>\n",
       "      <td>635.423889</td>\n",
       "      <td>437.147827</td>\n",
       "      <td>0.274013</td>\n",
       "      <td>67</td>\n",
       "      <td>cell phone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         xmin        ymin         xmax        ymax  confidence  class  \\\n",
       "0  745.578552   48.470337  1142.694336  720.000000    0.868910      0   \n",
       "1  124.744202  197.334534   844.397156  716.650574    0.630325      0   \n",
       "2  441.238708  439.350647   498.380798  708.570984    0.616793     27   \n",
       "3  594.081848  377.300415   635.423889  437.147827    0.274013     67   \n",
       "\n",
       "         name  \n",
       "0      person  \n",
       "1      person  \n",
       "2         tie  \n",
       "3  cell phone  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "\n",
    "# Images\n",
    "imgs = ['https://ultralytics.com/images/zidane.jpg']  # batch of images\n",
    "\n",
    "# Inference\n",
    "results = model(imgs)\n",
    "\n",
    "# Results\n",
    "results.print()\n",
    "results.save()  # or .show()\n",
    "\n",
    "results.xyxy[0]  # img1 predictions (tensor)\n",
    "results.pandas().xyxy[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5fd3c9e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AutoShape' object has no attribute 'classifier'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dml\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1709\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1707\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1708\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1709\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'AutoShape' object has no attribute 'classifier'"
     ]
    }
   ],
   "source": [
    "print(model.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4b4d01d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['info', 'licenses', 'categories', '__raw_Chinese_name_df', 'images', 'annotations'])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "json_file_path = 'instances_val2019.json'\n",
    "\n",
    "with open(json_file_path) as json_data:\n",
    "    data = json.load(json_data)\n",
    "\n",
    "print(data.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2cfe3f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      file_name  width  height     id level\n",
      "0     20180827-16-07-06-756.jpg   1850    1850    220  easy\n",
      "1     20180827-16-07-10-756.jpg   1840    1840    221  easy\n",
      "2     20180827-16-24-37-306.jpg   1826    1826    222  easy\n",
      "3     20180827-16-24-44-306.jpg   1829    1829    223  easy\n",
      "4     20180827-16-24-53-306.jpg   1826    1826    224  easy\n",
      "...                         ...    ...     ...    ...   ...\n",
      "5995  20181024-15-23-05-131.jpg   1813    1813  30609  hard\n",
      "5996  20181024-15-37-14-136.jpg   1821    1821  30613  hard\n",
      "5997  20181024-15-37-31-136.jpg   1832    1832  30614  hard\n",
      "5998  20181024-15-37-46-136.jpg   1830    1830  30615  hard\n",
      "5999  20181024-15-57-25-126.jpg   1808    1808  30616  hard\n",
      "\n",
      "[6000 rows x 5 columns]\n",
      "Index(['file_name', 'width', 'height', 'id', 'level'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data['images'])\n",
    "print(df)\n",
    "print(df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e39a6d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "2000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your data is already loaded into a pandas DataFrame\n",
    "# For example, if you're reading the data from a CSV file, you can use:\n",
    "# df = pd.read_csv('your_file.csv')\n",
    "\n",
    "# For this example, let's assume `df` is your DataFrame\n",
    "# Filter for 'easy' level\n",
    "easy_images = df[df['level'] == 'easy']\n",
    "\n",
    "# Filter for 'medium' level\n",
    "medium_images = df[df['level'] == 'medium']\n",
    "\n",
    "# Filter for 'hard' level\n",
    "hard_images = df[df['level'] == 'hard']\n",
    "\n",
    "# Display the first few rows of each filtered DataFrame\n",
    "print(len(easy_images))\n",
    "print(len(medium_images))\n",
    "print(len(hard_images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1acdf962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      file_name  width  height     id level\n",
      "0     20180827-16-07-06-756.jpg   1850    1850    220  easy\n",
      "1     20180827-16-07-10-756.jpg   1840    1840    221  easy\n",
      "2     20180827-16-24-37-306.jpg   1826    1826    222  easy\n",
      "3     20180827-16-24-44-306.jpg   1829    1829    223  easy\n",
      "4     20180827-16-24-53-306.jpg   1826    1826    224  easy\n",
      "...                         ...    ...     ...    ...   ...\n",
      "5995  20181024-15-23-05-131.jpg   1813    1813  30609  hard\n",
      "5996  20181024-15-37-14-136.jpg   1821    1821  30613  hard\n",
      "5997  20181024-15-37-31-136.jpg   1832    1832  30614  hard\n",
      "5998  20181024-15-37-46-136.jpg   1830    1830  30615  hard\n",
      "5999  20181024-15-57-25-126.jpg   1808    1808  30616  hard\n",
      "\n",
      "[6000 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "images_df = pd.DataFrame(data['images'])\n",
    "print(images_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d9f5828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "val2019_dir = 'val2019'\n",
    "\n",
    "for level in ['easy', 'medium', 'hard']:\n",
    "    level_dir = os.path.join(val2019_dir, level)\n",
    "    if not os.path.exists(level_dir):\n",
    "        os.makedirs(level_dir)\n",
    "\n",
    "# Move images to respective level folders\n",
    "for image_info in data['images']:\n",
    "    file_name = image_info['file_name']\n",
    "    level = image_info.get('level')  # Get the level ('easy', 'medium', or 'hard')\n",
    "\n",
    "    if level in ['easy', 'medium', 'hard']:\n",
    "        src = os.path.join(val2019_dir, file_name)\n",
    "        dest = os.path.join(val2019_dir, level, file_name)\n",
    "        \n",
    "        # Check if the image file exists before moving\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, dest)\n",
    "        else:\n",
    "            print(f\"Image file {file_name} not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c936fe1-0e94-4374-82ab-2eeb47cd08ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_path = 'instances_test2019.json'\n",
    "\n",
    "with open(json_file_path) as json_data:\n",
    "    data = json.load(json_data)\n",
    "\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e844c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2019_dir = 'test2019'\n",
    "\n",
    "for level in ['easy', 'medium', 'hard']:\n",
    "    level_dir = os.path.join(test2019_dir, level)\n",
    "    if not os.path.exists(level_dir):\n",
    "        os.makedirs(level_dir)\n",
    "\n",
    "# Move images to respective level folders\n",
    "for image_info in data['images']:\n",
    "    file_name = image_info['file_name']\n",
    "    level = image_info.get('level')  # Get the level ('easy', 'medium', or 'hard')\n",
    "\n",
    "    if level in ['easy', 'medium', 'hard']:\n",
    "        src = os.path.join(test2019_dir, file_name)\n",
    "        dest = os.path.join(test2019_dir, level, file_name)\n",
    "        \n",
    "        # Check if the image file exists before moving\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, dest)\n",
    "        else:\n",
    "            print(f\"Image file {file_name} not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ab81992b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images successfully copied to newtrain_dataset\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Paths to the directories\n",
    "train2019_dir = 'train2019'\n",
    "val2019_medium_dir = 'val2019/medium'\n",
    "test2019_medium_dir = 'test2019/medium'\n",
    "\n",
    "# New directory path\n",
    "new_dir = 'newtrain_dataset'\n",
    "\n",
    "# Create the new directory if it doesn't exist\n",
    "if not os.path.exists(new_dir):\n",
    "    os.makedirs(new_dir)\n",
    "\n",
    "# Function to copy files from a directory to the new directory\n",
    "def copy_images(src_dir, dest_dir):\n",
    "    for file_name in os.listdir(src_dir):\n",
    "        src_file = os.path.join(src_dir, file_name)\n",
    "        dest_file = os.path.join(dest_dir, file_name)\n",
    "        if os.path.isfile(src_file):\n",
    "            shutil.copy(src_file, dest_file)\n",
    "\n",
    "# Copy images from train2019, val2019/medium, and test2019/medium\n",
    "copy_images(train2019_dir, new_dir)\n",
    "copy_images(val2019_medium_dir, new_dir)\n",
    "copy_images(test2019_medium_dir, new_dir)\n",
    "\n",
    "print(f\"Images successfully copied to {new_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2325c072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split completed: 57365 training images and 6374 temporary images.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "original_dataset_dir = 'singleobject'\n",
    "data_path = Path.cwd()\n",
    "\n",
    "# List all images in the original dataset directory\n",
    "all_images = os.listdir(original_dataset_dir)\n",
    "\n",
    "def fill_sub_dir(sub_dir, file_subset):\n",
    "    \"\"\"This function copies files to a specified <sub_dir>.\"\"\"\n",
    "    for file_name in file_subset:\n",
    "        # Create source and destination paths\n",
    "        src_file_path = Path(original_dataset_dir) / file_name\n",
    "        dest_file_path = data_path / sub_dir / file_name\n",
    "        # Copy the file\n",
    "        shutil.copyfile(src_file_path, dest_file_path)\n",
    "\n",
    "split_ratio_big_dataset = 0.1  # Adjust the split ratio as needed\n",
    "\n",
    "if split_ratio_big_dataset is None:\n",
    "    raise ValueError(\"`split_ratio_big_dataset` must have a value between 0 and 1.\")\n",
    "\n",
    "# Split it\n",
    "train, temp = train_test_split(all_images, test_size=split_ratio_big_dataset, random_state=3)\n",
    "\n",
    "subdirectories = {\n",
    "    \"train\": train,\n",
    "    \"temp\": temp,\n",
    "}\n",
    "\n",
    "# Create subdirectories if they don't exist\n",
    "for subdirectory in subdirectories.keys():\n",
    "    subdirectory_path = data_path / subdirectory\n",
    "    subdirectory_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Copy files to the respective subdirectories\n",
    "for sub_dir, file_subset in subdirectories.items():\n",
    "    fill_sub_dir(sub_dir, file_subset)\n",
    "\n",
    "print(f\"Split completed: {len(train)} training images and {len(temp)} temporary images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0a570af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split completed: 3187 test images and 3187 val images.\n"
     ]
    }
   ],
   "source": [
    "#split test and val\n",
    "original_dataset_dir = 'temp'\n",
    "temp_images = os.listdir(original_dataset_dir)\n",
    "val, test = train_test_split(temp_images, test_size=0.5, random_state=3)\n",
    "\n",
    "subdirectories = {\n",
    "    \"val\": val,\n",
    "    \"test\": test,\n",
    "}\n",
    "\n",
    "# Create subdirectories if they don't exist\n",
    "for subdirectory in subdirectories.keys():\n",
    "    subdirectory_path = data_path / subdirectory\n",
    "    subdirectory_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Copy files to the respective subdirectories\n",
    "for sub_dir, file_subset in subdirectories.items():\n",
    "    fill_sub_dir(sub_dir, file_subset)\n",
    "\n",
    "print(f\"Split completed: {len(test)} test images and {len(val)} val images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb981cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
